{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook 02 â€“ Introduction to spaCy\n",
    "\n",
    "Part of the ALLANAI NLP Learning Series\n",
    "Author: Mahira Banu (ALLANAI Labs)\n",
    "\n",
    "ðŸ 1. What is spaCy?\n",
    "\n",
    "spaCy is an open-source industrial-strength Natural Language Processing (NLP) library in Python.\n",
    "It is designed for speed, scalability, and production use.\n",
    "\n",
    "spaCy organizes its NLP tasks into a processing pipeline, which includes:\n",
    "\n",
    "Tokenization\n",
    "\n",
    "Part-of-Speech (POS) Tagging\n",
    "\n",
    "Named Entity Recognition (NER)\n",
    "\n",
    "Dependency Parsing\n",
    "\n",
    "When you load a model with spacy.load(\"en_core_web_sm\"), you get an NLP object containing the model and pipeline components.\n",
    "\n",
    "âš™ï¸ 2. spaCy Processing Pipeline\n",
    "\n",
    "Hereâ€™s how spaCy processes text internally:\n",
    "\n",
    "Text Input â†’ The raw string is passed to the NLP object\n",
    "\n",
    "Tokenizer â†’ Splits text into words, punctuation, etc.\n",
    "\n",
    "Tagger â†’ Assigns POS tags like NOUN, VERB, ADJ\n",
    "\n",
    "Parser â†’ Builds dependency trees\n",
    "\n",
    "NER â†’ Detects named entities like people, places, or organizations\n",
    "\n",
    "Doc Object â†’ Final structured representation of the text\n",
    "\n",
    "ðŸ’¡ The resulting object is called a Doc, which contains Tokens, Sentences, Entities, and linguistic annotations.\n",
    "\n",
    "ðŸ§© 3. Example: Tokenization and POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m      3\u001b[39m nlp = spacy.load(\u001b[33m\"\u001b[39m\u001b[33men_core_web_sm\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m#sample text\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#sample text\n",
    "\n",
    "text = 'this is an example text'\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "print(\"Token | POS Tag\")\n",
    "print(\"---------------\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<10} {token.pos_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
