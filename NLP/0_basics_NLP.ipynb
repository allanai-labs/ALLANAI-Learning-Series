{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Overview of NLP\n",
    "\n",
    "Natural Language Processing (NLP) is a field of Artificial Intelligence (AI) that enables computers to understand, interpret, and generate human language.\n",
    "It connects linguistics, computer science, and machine learning to process large amounts of natural text or speech data.\n",
    "\n",
    "üß© Why NLP Matters\n",
    "\n",
    "üåç Enables communication between humans and machines\n",
    "\n",
    "üí¨ Powers applications like chatbots, translation tools, sentiment analysis, and voice assistants\n",
    "\n",
    "üß† Helps extract insights from massive text data in social media, customer reviews, or research papers\n",
    "\n",
    "‚öôÔ∏è Common NLP Tasks\n",
    "\n",
    "| Task                               | Description                                                | Example                                      |\n",
    "| ---------------------------------- | ---------------------------------------------------------- | -------------------------------------------- |\n",
    "| **Tokenization**                   | Breaking text into words or sentences                      | `\"I love London!\" ‚Üí ['I', 'love', 'London']` |\n",
    "| **POS Tagging**                    | Identifying grammatical roles                              | `\"love\" ‚Üí Verb`, `\"London\" ‚Üí Noun`           |\n",
    "| **Named Entity Recognition (NER)** | Extracting entities like people, places, or organizations  | `\"London\"` ‚Üí Location                        |\n",
    "| **Sentiment Analysis**             | Detecting emotions or opinions                             | `\"I love this movie!\" ‚Üí Positive`            |\n",
    "| **Machine Translation**            | Translating text from one language to another              | `\"Hello\" ‚Üí \"Bonjour\"`                        |\n",
    "| **Text Summarization**             | Creating concise summaries from long texts                 | Automatic news summaries                     |\n",
    "| **Question Answering**             | Systems like ChatGPT or Siri that answer natural questions | `\"Who is the PM of UK?\"` ‚Üí `\"Rishi Sunak\"`   |\n",
    "\n",
    "2. Evolution of NLP\n",
    "\n",
    "The journey of NLP can be divided into three major eras:\n",
    "\n",
    "üèóÔ∏è Rule-Based NLP (1950s‚Äì1980s)\n",
    "\n",
    "Based on manually written grammar and pattern rules.\n",
    "\n",
    "Example: Early translation systems or ELIZA chatbot.\n",
    "\n",
    "Limitation: Poor scalability; couldn‚Äôt handle language ambiguity.\n",
    "\n",
    "üìä Statistical NLP (1990s‚Äì2010s)\n",
    "\n",
    "Shift to data-driven models using probabilities and feature engineering.\n",
    "\n",
    "Algorithms: Naive Bayes, Hidden Markov Models, CRFs.\n",
    "\n",
    "Example: Spam filters, POS taggers, early search engines.\n",
    "\n",
    "Limitation: Required lots of feature tuning and labeled data.\n",
    "\n",
    "üß† Neural NLP (2010s‚ÄìPresent)\n",
    "\n",
    "Deep learning revolutionized NLP using embeddings and sequence models.\n",
    "\n",
    "Architectures: RNN, LSTM, GRU ‚Üí Transformers (BERT, GPT, T5).\n",
    "\n",
    "Modern NLP uses pre-trained models with billions of parameters that understand language context.\n",
    "\n",
    "üìà Fun fact: Models like ChatGPT or BERT are trained on hundreds of GBs of text to learn contextual meaning.\n",
    "\n",
    "3. Popular Libraries Used in NLP\n",
    "\n",
    "Here are the most widely used Python libraries for NLP tasks:\n",
    "\n",
    "| Library                             | Purpose                         | Key Features                                        |\n",
    "| ----------------------------------- | ------------------------------- | --------------------------------------------------- |\n",
    "| **NLTK (Natural Language Toolkit)** | Educational & basic NLP         | Tokenization, stemming, POS tagging, corpora access |\n",
    "| **spaCy**                           | Fast industrial-strength NLP    | Pre-trained models, NER, POS, dependency parsing    |\n",
    "| **TextBlob**                        | Simpler interface for beginners | Sentiment analysis, noun phrase extraction          |\n",
    "| **Gensim**                          | Topic modeling & embeddings     | Word2Vec, Doc2Vec, LDA                              |\n",
    "| **Scikit-learn**                    | ML foundation for NLP           | TF-IDF, Naive Bayes, SVMs                           |\n",
    "| **Transformers (Hugging Face)**     | State-of-the-art deep NLP       | BERT, GPT, T5, etc. pre-trained models              |\n",
    "| **StanfordNLP / Stanza**            | Linguistically rich NLP         | Accurate syntactic and semantic analysis            |\n",
    "\n",
    "#### Mini Demo ‚Äì Tokenization using spaCy\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London          PROPN\n",
      "is              AUX\n",
      "a               DET\n",
      "beautiful       ADJ\n",
      "city            NOUN\n",
      ".               PUNCT\n",
      "Mahira          PROPN\n",
      "is              AUX\n",
      "learning        VERB\n",
      "NLP             PROPN\n",
      "with            ADP\n",
      "ALLANAI         PROPN\n",
      "Labs            PROPN\n",
      ".               PUNCT\n",
      "\n",
      "Named Entities:\n",
      "London ‚Üí GPE\n",
      "Mahira ‚Üí PERSON\n",
      "NLP ‚Üí ORG\n",
      "ALLANAI Labs ‚Üí ORG\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load small English model\n",
    "import spacy\n",
    "# spacy.cli.download(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Example text\n",
    "text = \"London is a beautiful city. Mahira is learning NLP with ALLANAI Labs.\"\n",
    "\n",
    "# Process text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print tokens and POS tags\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<15} {token.pos_}\")\n",
    "\n",
    "# Extract Named Entities\n",
    "print(\"\\nNamed Entities:\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text} ‚Üí {ent.label_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaways:**\n",
    "\n",
    "- NLP bridges the gap between language and logic.\n",
    "- Modern NLP relies on deep learning & transformers.\n",
    "- Tools like spaCy, Transformers, and NLTK make it easy to perform complex tasks.\n",
    "- Understanding the evolution helps you choose the right approach ‚Äî from simple rules to contextual embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
